{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2pcN9BElr2t"
      },
      "source": [
        "<div style=\"background:#00000\">\n",
        "<div>\n",
        "<h1>üß∞ Starting Kit: <b>AUTO-SURVEY CHALLENGE'23</b> </h1>\n",
        "<p>\n",
        "This starting kit will guide you step by step and will walk you through the data statistics and examples. This will give you a clear idea of what this challenge is about and how you can proceed further to solve the challenge.\n",
        "</p>\n",
        "</div>\n",
        "<div>\n",
        "<br/><br/>\n",
        "<details>\n",
        "<summary open>Prerequisite</summary>\n",
        "<p>\n",
        "To run this notebook that calls the ChatGPT API you must get an <a href=\"https://platform.openai.com/docs/introduction\">OpenAI API</a> by following <a href=\"https://github.com/kentrachmat/public_ai_paper_challenge_codabench/blob/master/how_to_get_openai_api.md\">this instruction</a>.\n",
        "\n",
        "</p>\n",
        "</details>\n",
        "<details>\n",
        "<summary>Technical Details</summary>\n",
        "<p>`\n",
        "This code was tested with <a href=\"https://www.python.org/downloads/release/python-385/\">Python 3.8.5</a> | <a href=\"https://anaconda.org/\">Anaconda</a> custom (64-bit) | (default, Dec 23 2020, 21:19:02).\n",
        "</p>\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Disclaimer</summary>\n",
        "  <p>\n",
        "  ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The CHALEARN, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL,\n",
        "  INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE.\n",
        "  </p>\n",
        "</details>\n",
        "<details>\n",
        "<summary><a href=\"https://sites.google.com/view/ai-agents/credits?authuser=0\">References and Credits </summary>\n",
        "</details>\n",
        "</div>\n",
        "<hr>\n",
        "\n",
        "<button type=\"button\" ><h3><a href=\"https://www.codabench.org/competitions/866/\">Competition Site</a></h3></button>\n",
        "<button type=\"button\" ><h3><a href=\"https://sites.google.com/view/ai-agents/home\">Landing Page Site</a></h3></button>\n",
        "<button type=\"button\"><h3><a href=\"mailto:ai-agent-journal@chalearn.org\">Contact us</a></h3></button>\n",
        "<hr>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: Input your API key"
      ],
      "metadata": {
        "id": "FRI4p73Rknrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "# Please enter your API key\n",
        "new_api_key = getpass.getpass(\"Please input your API key: \")"
      ],
      "metadata": {
        "id": "D0Zxsq9tmQNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QgGvO7mlr2y"
      },
      "source": [
        "# Step 1: Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyA9RhtJlr2z"
      },
      "outputs": [],
      "source": [
        "!git clone -q https://github.com/kentrachmat/public_ai_paper_challenge_codabench.git\n",
        "%cd public_ai_paper_challenge_codabench\n",
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NHi2Gtg-lr21"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns; sns.set()\n",
        "import warnings\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T CHANGE\n",
        "\n",
        "MODEL_DIR = 'sample_code_submission/'\n",
        "RESULT_DIR = 'sample_result_submission/'\n",
        "PROBLEM_GENERATOR_DIR = 'generator_ingestion_program/'\n",
        "SCORE_GENERATOR_DIR = 'generator_scoring_program/'\n",
        "PROBLEM_REVIEWER_DIR = 'reviewer_ingestion_program/'\n",
        "SCORE_REVIEWER_DIR = 'reviewer_scoring_program/'\n",
        "DATA_DIR = 'sample_data'\n",
        "DATA_NAME = 'ai_paper_challenge'\n",
        "SCORING_OUTPUT_DIR = 'scoring_output'\n",
        "\n",
        "file_paths = ['sample_code_submission/sample_submission_chatgpt_api_key.json',\n",
        "              'generator_scoring_program/scoring_program_chatgpt_api_key.json',\n",
        "              'reviewer_scoring_program/scoring_program_chatgpt_api_key.json']\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'r') as file:\n",
        "        json_data = json.load(file)\n",
        "\n",
        "    json_data['key'] = new_api_key\n",
        "\n",
        "    with open(file_path, 'w') as file:\n",
        "        json.dump(json_data, file, indent=4)"
      ],
      "metadata": {
        "id": "LjDtV8-RnwV7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x33tZ1tclr23"
      },
      "source": [
        "***\n",
        "# Step 2: Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't provide any TRAINING data, you are free to train on any external data. We only provide TEST data to evaluate your model.\n",
        "\n",
        "`sample_data` contains:\n",
        "- 3 prompts for the AI-Author track\n",
        "- 3 set of papers for the AI-Reviewer track, each was generated by a single prompt.\n",
        "\n",
        "### ü§ñ `sample_data/generator`\n",
        "\n",
        "This directory contains the necessary data for the AI-Author track\n",
        "\n",
        "- `instructions.txt`: A text file that provides instructions or guidelines for generating a paper.\n",
        "- `prompts.csv`: Automatically generated prompts by reverse-engineering original papers. These prompts are the input to your model.\n",
        "- `metadata.csv`: Metadata from [Semantic Scholar](https://www.semanticscholar.org/) associates with the automatically generated prompts.\n",
        "- `papers`: A subdirectory that contains variations of papers for each prompts.\n",
        "  - 0, .. , N: Each number corresponds to a set of papers generated by a single prompt.\n",
        "\n",
        "### üñäÔ∏è `sample_data/reviewer`\n",
        "\n",
        "This directory contains the necessary data for the AI-Reviewer track\n",
        "\n",
        "- `instructions.txt`: A text file that provides instructions or guidelines for reviewing a paper.\n",
        "- `papers`: A subdirectory that contains variations of paper that needs to be reviewed.\n",
        "- `metadata.csv`: Informations each papers in the `papers` directory."
      ],
      "metadata": {
        "id": "YlbSEllOrBHu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-v7np69lr23"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n3xPshqlr24"
      },
      "outputs": [],
      "source": [
        "from generator_ingestion_program.data_io import read_data as read_data_generator\n",
        "from reviewer_ingestion_program.data_io import read_data as read_data_reviewer\n",
        "\n",
        "data_generator, _ = read_data_generator(DATA_DIR, random_state=42)\n",
        "data_reviewer, _ = read_data_reviewer(DATA_DIR, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GLMwJOAlr24"
      },
      "source": [
        "### Data Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba-tVjpIlr24"
      },
      "outputs": [],
      "source": [
        "print(\"Total Generation prompts: \", len(np.unique(data_generator['generator']['ids'])))\n",
        "print(\"Total Reviewer papers : \", len(np.unique(data_reviewer['reviewer']['ids'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7CKFU-lr25"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-75vFiflr25"
      },
      "source": [
        "#### AI-Author"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Instruction for a good survey paper"
      ],
      "metadata": {
        "id": "D1Q-TSflpvab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_generator['generator']['instructions'])"
      ],
      "metadata": {
        "id": "uLjVj-fvpxWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompts"
      ],
      "metadata": {
        "id": "pDnde_sdpvg0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG9pzvullr25"
      },
      "outputs": [],
      "source": [
        "for p in data_generator['generator']['prompts']:\n",
        "    print(p)\n",
        "    print(\"Length:\",len(p))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX9i47KHlr25"
      },
      "source": [
        "#### AI-Reviewer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format of a review"
      ],
      "metadata": {
        "id": "KOiypO-rp9w6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulJKpNLslr25"
      },
      "outputs": [],
      "source": [
        "print(data_reviewer['reviewer']['instructions'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample paper to be reviewed (bad language)"
      ],
      "metadata": {
        "id": "AJA4UVa9p_cw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTGJs2MRlr26"
      },
      "outputs": [],
      "source": [
        "sample_paper = data_reviewer['reviewer']['papers'][0]\n",
        "for i, section in enumerate(sample_paper):\n",
        "    if i in [0, 1, len(sample_paper)-1]:\n",
        "        print(section)\n",
        "    elif i==2:\n",
        "      print('...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNSThTQ-lr26"
      },
      "source": [
        "***\n",
        "# Step 3: Building a predictive model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this competition, you need to implement a `model` class, with 2 functions:\n",
        "- `generate_papers(prompts, instruction)`:\n",
        "  - Arguments:\n",
        "    - `prompts`: a list of strings represent given prompts\n",
        "    - `instruction`: a string represents the instruction to generate good survey papers\n",
        "  - Returns:\n",
        "    - `generated_papers`: a list of strings in JSON format. The format of the string is describe in **Paper format**\n",
        "- `review_papers(papers, instruction)`:\n",
        "  - Arguments:\n",
        "    - `papers`: a list of dictionaries represent papers to be reviewed. The format of each paper's dictionary is describe in **Paper format**.\n",
        "    - `instruction`: a string represents the instruction to review papers.\n",
        "  - Returns:\n",
        "    - `reviews`: a list of dictionaries represent reviews. The format of each paper's review is describe in **Review format**.\n",
        "\n",
        "\n",
        "\n",
        "## Paper format:\n",
        "\n",
        "All papers in the competition follow this JSON format:\n",
        "```python\n",
        "[   \n",
        "    {\"heading\":\"Title\", \"text\":\"...\"},\n",
        "    {\"heading\":\"Abstract\", \"text\":\"...\"},\n",
        "    .....\n",
        "    .....\n",
        "    {\"heading\":\"Conclusion\", \"text\":\"...\"},\n",
        "    {\"heading\":\"References\", \"text\":\"...\"}\n",
        "]\n",
        "```\n",
        "\n",
        "## Review format:\n",
        "All reviews in the competition follow this JSON format:\n",
        "\n",
        "```python\n",
        "{\n",
        "    \"Responsibility\": {\n",
        "        \"score\": float,\n",
        "        \"comment\": \"comment A\"\n",
        "    },\n",
        "    \"Soundness\": {\n",
        "        \"score\": float,\n",
        "        \"comment\": \"comment B\"\n",
        "    },\n",
        "    \"Clarity\":{\n",
        "        \"score\": float,\n",
        "        \"comment\": \"comment C\"\n",
        "    },\n",
        "    \"Contribution\": {\n",
        "        \"score\": float,\n",
        "        \"comment\": \"comment D\"\n",
        "    },\n",
        "    \"Overall\": {\n",
        "        \"score\": float,\n",
        "        \"comment\": \"comment E\"\n",
        "    },\n",
        "    \"Confidence\": {\n",
        "        \"score\": float,\n",
        "        \"comment\": \"comment F\"\n",
        "    },\n",
        "}\n",
        "```\n",
        "It is strongly recommended that you follow the exact naming and structure above."
      ],
      "metadata": {
        "id": "6Vj2jD18rNzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model\n",
        "We have provided 2 baseline models:\n",
        "- \"Dummy\" baseline:\n",
        "  - `generate_papers()` returns the same template paper\n",
        "  - `review_papers()` returns 0 score with no comment for every criterion\n",
        "\n",
        "You can access this baseline in the `dummy_code_submission` folder\n",
        "- ChatGPT baseline:\n",
        "  - `generate_papers()` returns generated papers by ChatGPT, using the given prompts and instruction as inputs.\n",
        "  - `review_papers()` returns generated reviews by ChatGPT, using the given papers and instruction as inputs.\n",
        "\n",
        "You can access this baseline in the `sample_code_submission` folder.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dOkeD4geRdp5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMxPhwvTlr26"
      },
      "outputs": [],
      "source": [
        "baseline = 'chatgpt' #@param [\"chatgpt\", \"dummy\"]\n",
        "\n",
        "\n",
        "from generator_ingestion_program.data_io import write as write_generator\n",
        "from reviewer_ingestion_program.data_io import write as write_reviewer\n",
        "\n",
        "if baseline == \"dummy\":\n",
        "  from dummy_code_submission.model import model\n",
        "elif baseline == \"chatgpt\":\n",
        "  from sample_code_submission.model import model\n",
        "else:\n",
        "  raise NotImplementedError\n",
        "\n",
        "myModel = model()\n",
        "generator_X = data_generator[\"generator\"][\"prompts\"]\n",
        "reviewer_X = data_reviewer[\"reviewer\"][\"papers\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfIWvu8Xlr27"
      },
      "outputs": [],
      "source": [
        "# Generator\n",
        "generator_Y_hat = myModel.generate_papers(generator_X, data_generator[\"generator\"][\"instructions\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0Pdgbublr27"
      },
      "outputs": [],
      "source": [
        "# Reviewer\n",
        "reviewer_Y_hat = myModel.review_papers(reviewer_X, data_reviewer[\"reviewer\"][\"instructions\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGY-cQAdlr27"
      },
      "outputs": [],
      "source": [
        "result_name = RESULT_DIR + DATA_NAME\n",
        "\n",
        "# Output predicted papers\n",
        "write_generator(result_name + '_generator.predict', generator_Y_hat)\n",
        "\n",
        "# Output reviews\n",
        "write_reviewer(result_name + '_reviewer.predict', reviewer_Y_hat)\n",
        "\n",
        "# Check if they exists\n",
        "!ls $result_name*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmNkvShmlr27"
      },
      "source": [
        "***\n",
        "# Step 4: Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bztGuRjAlr29"
      },
      "source": [
        "\n",
        "### Scoring program\n",
        "You can evaluate your model locally using this sample scoring program (using ChatGPT only). **Our Scoring Program** with sophisticated analysis is **hidden** until the competition ends.\n",
        "\n",
        "### Scoring results\n",
        "- If you run locally, you can find all results in the `scoring_output/` folder.\n",
        "\n",
        "- If you submit your solution to Codabench, you can download the results by choosing \"Output from scoring step\". The evaluation on Codabench is implemented using **Our Scoring Program**.\n",
        "\n",
        "## AI-Author evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctq8gHIslr29"
      },
      "outputs": [],
      "source": [
        "!python3 $SCORE_GENERATOR_DIR/score.py $DATA_DIR $RESULT_DIR $SCORING_OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI-Reviewer evaluation"
      ],
      "metadata": {
        "id": "8rWj2yK4xa-r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzQpJ_F-lr29"
      },
      "outputs": [],
      "source": [
        "!python3 $SCORE_REVIEWER_DIR/score.py $DATA_DIR $RESULT_DIR $SCORING_OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8oG53gulr29"
      },
      "source": [
        "***\n",
        "# Step 5: Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below create a zip file that you can submit to Codabench."
      ],
      "metadata": {
        "id": "cahsDSK5yD08"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehRoMPIclr29"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from generator_ingestion_program.data_io import zipdir\n",
        "\n",
        "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
        "sample_code_submission = 'sample_code_submission_' + the_date + '.zip'\n",
        "zipdir(sample_code_submission, MODEL_DIR, exclude_folders=['__pycache__'], exclude_files=[f'{DATA_NAME}_model.pickle'])\n",
        "print(\"Submit this file to codalab:\\n\" + sample_code_submission)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "style-trans-fair",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3cbd974dc296b583d3833699839c7d0910845e9c76e734e5f42c99ff8eae1461"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}