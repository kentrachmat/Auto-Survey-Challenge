[{"heading": "Title", "text": "\"Unlocking the Potential of Microscopy with Artificial Intelligence: A Comprehensive Guide\""}, {"heading": "Abstract", "text": "The paper discusses how Artificial Intelligence (AI) based on Deep Learning (DL) is transforming the field of biomedical research and microscopy. The technology is no longer limited to computer science experts and is now being used by biomedical researchers. The paper provides an accessible overview of DL concepts, capabilities, and limitations, with a focus on its applications in image segmentation, classification, and restoration. The authors highlight how DL has the potential to enhance resolution, signal, and information content in acquired data, thereby pushing the limits of microscopy. However, the paper also discusses the pitfalls of DL and the future directions expected in this field. Overall, the paper emphasizes the significant impact of DL on biomedical research and microscopy."}, {"heading": "Introduction", "text": "The ability to adapt previous knowledge to new situations and recognize patterns is a hallmark of human intelligence. Artificial Intelligence (AI) aims to replicate these abilities in non-human agents, with machine learning being a subset of AI methods. Deep Learning (DL) is a type of machine learning that uses neural networks (NNs) to extract useful features from large sets of data and make predictions or decisions on unseen data. NNs are initially presented with a large set of paired input and desired output called the training dataset, from which it learns how to map each input into its corresponding desired output. Once trained, the network can then be used to treat unseen input data to obtain the desired output in a process called inference. NNs have significantly improved biomedical image analysis, including automated, accurate classification and segmentation of cell images, extraction of structures from label-free microscopy imaging, and image restoration. However, the training process can be computationally intensive, and there are still limitations to the technology. The potential for NNs in microscopy is significant, and research efforts are ongoing to develop new applications."}, {"heading": "How Does A Neural Network Learn?", "text": "Neural networks (NNs) are complex networks of connected neurons arranged in layers. Each layer provides a new representation of the data to the next layer with growing levels of abstraction. Convolutional neural networks (CNNs) are important for tasks involving feature recognition in image data. The NN learns to map from input to output by iteratively adjusting its neurons' parameters such that it minimizes the difference between its own output and the desired output using the training dataset. The backpropagation method allows the network errors to be projected back to every neuron's individual contribution. Stochastic gradient descent is the most common method for adjusting the neuron's parameters. Overfitting is a potential issue with deep networks. During training, the network performance is monitored using an unseen validation dataset. The training dataset should contain many different examples of the desired outputs. Technical developments have improved or sped up the learning stage, including pre-trained networks, GANs, and self-learning."}, {"heading": "Neural Networks And Microscopy", "text": "The challenges faced by life science researchers in imaging biological specimens include balancing phototoxicity and bleaching of fluorescent labels with good signal or resolution, reliably imaging multiple fluorescent markers, and extracting relevant and complex information from large image datasets without human bias. The increasing availability of high-throughput imaging has led to the development of new generation deep learning (DL) methods in microscopy that have the potential to address these problems. This paper presents an overview of recent exciting developments in AI that can address current microscopy limitations. The methods are separated into four categories: object detection and classification, image segmentation, artificial labeling, and image restoration. These methods can facilitate information extraction, allow large and potentially unbiased high-throughput analysis, tackle the limitations of the maximum number of fluorescent labels and phototoxicity, and reduce phototoxicity, improve denoising or resolution."}, {"heading": "Object Detection And Classification", "text": "The paper discusses the importance of recognizing and assigning identities to relevant features on microscopy images, such as identifying mitotic cells in a tissue sample for cancer diagnosis. Manual annotation is tedious and can introduce bias, so computational methods have been introduced to accelerate detection or classification tasks. However, these methods often rely on handcrafted parameters chosen by researchers. Neural networks (NNs) have the advantage of learning relevant image features autonomously and have been extensively used in the biomedical imaging field, especially for cancer detection and high-throughput screens. Unsupervised learning is a new approach that allows explorative studies on protein localization data without user bias or manual labeling of a training dataset. NNs have also shown their capacity to accurately identify cellular states from transmitted-light data, which could be a less invasive method to identify cell fate or identity."}, {"heading": "Image Segmentation", "text": "The paper discusses the importance of segmentation in image analysis, particularly in identifying cellular or subcellular structures. The traditional approach to segmentation involves user-based fine-tuning and manual error-removal, which can be time-consuming and biased. Convolutional neural networks (CNNs) have been found to outperform classical approaches in terms of accuracy and generalization, especially in cell segmentation in co-cultures of multiple cell types. CNNs have also been successfully used in histopathology to segment colon glands, breast tissues, and nuclei. Segmentation is often used with subsequent classification and can improve the accuracy of classification. The U-net architecture, which uses many convolution/pooling layers followed by many layers of de-convolution/upsampling, has been pioneered in the segmentation field and has wider importance in microscopy. These architectures can be adapted to other image-to-image transformations, making them important networks for microscopy applications."}, {"heading": "Artificial Labelling", "text": "Label-free imaging using brightfield and fluorescence modalities has been shown to be effective in extracting specific cellular structures such as nuclear membrane, nucleoli, plasma membranes, and mitochondria using convolutional neural networks (CNNs). This approach eliminates the need for genetic or chemical labelling, which can disturb the biological system, and reduces phototoxicity to cells. The training dataset for this approach contains paired images obtained from brightfield and fluorescence modalities of the same cells, and the networks learn to predict a fluorescent label from transmitted light or EM images. The networks achieved high accuracy using a training dataset of only 30-40 images and were able to identify dying cells or distinguish different cell types and subcellular structures. The networks' performance is versatile and can be applied between different microscopes and labels using transfer learning. However, the origin of the features produced by the networks from label-free modalities is not well understood, leading to scepticism and debate around artificial labelling."}, {"heading": "Image Restoration: Resolution And Signal", "text": "The limitations of signal-to-noise ratio (SNR) and resolution in optical set-ups restrict the amount and quality of features that can be extracted from microscopic images. Super-resolution microscopy (SRM) has enabled imaging of cellular structures at the nanoscale using light microscopy, but phototoxicity, bleaching, and low temporal resolution still limit high-resolution long-term imaging in living specimens. Content-aware image restoration (CARE) methodology, a CNN method, has been proposed to address these issues. The training datasets consist of paired images acquired at low and high SNR, respectively, and the network learns to predict a denoised (high SNR) image from a noisy input (low SNR). CARE has demonstrated successful restoration of axial resolution in deep microscopy sections and reconstruction of SRM images from diffraction-limited images. Unsupervised learning methods for image restoration requiring no labelled training data have also been explored. These methods represent an interesting avenue for tasks where large training sets are difficult or impossible to assemble."}, {"heading": "Using Neural Networks In Single-Molecule Localization Microscopy", "text": "The use of Convolutional Neural Networks (CNNs) in Single-Molecule Localization Microscopy (SMLM) has gained interest in the scientific community. Recent studies have shown that CNNs can directly map sparse SMLM data into their SRM output images, demonstrating the strength of CNNs for pattern recognition in redundant data. Some algorithms require no parameter tuning or specific knowledge about the imaged structures, making them advantageous over conventional SMLM reconstruction algorithms, especially for high emitter density. Other studies have used a different approach to SMLM reconstruction by training networks to detect the spatial positions of fluorophores from SMLM input images. This approach partially circumvents the controversy because the reconstructed images are more similar to standard SMLM reconstructions, making the resolution improvement easier to interpret. The main achievement of Deep Learning (DL) for SMLM is the reconstruction speed with which super-resolved images can be produced, which is improved by several orders of magnitude compared with conventional reconstruction algorithms."}, {"heading": "Discussion", "text": "The use of artificial intelligence (AI) in microscopy has transformed image analysis tasks and big-data analysis. However, there are significant challenges that cannot be solved by improved processing units. The quality of the training dataset determines the task carried out by the neural network (NN) and its performance. Any bias present in the training dataset will be subsequently incorporated into the network, highlighting the need for detailed data curation. Another concern is the lack of interpretability of network outputs, particularly in the case of resolution enhancement and artificial labeling. The design of CNN architectures requires technical know-how, limiting accessibility for many potential users in the life sciences. Despite these challenges, AI has great potential for microscopy, given its super-human performance in classification tasks and image reconstruction. However, caution should be exercised when interpreting the performance of NNs, as for any computational analysis tool."}, {"heading": "Outlook", "text": "The use of deep learning (DL) in microscopy has increased rapidly, indicating its potential as a powerful tool in biomedical imaging. However, there is a delay in translating AI research to microscopy, and some areas such as transfer learning are only starting to become available. Finding ways to reuse neural networks (NNs) on multiple tasks, image sizes, and microscopes would make DL more flexible and accessible, reducing the need for large training datasets and expert knowledge. The AI field is expected to develop tools to detect network failures and build trust in AI's role in research. New AI-enabled technologies could optimize microscopy at the image acquisition level by allowing integrated microscopy platforms to be controlled by an artificial agent. Overall, DL has the potential to become a widely used tool in life sciences if accessibility barriers are lowered and trust is established."}, {"heading": "Perspectives", "text": "The field of Deep Learning (DL) applied to microscopy has the potential to revolutionize the way we acquire and analyze microscopy data. DL was initially developed to automate tedious image segmentation and classification in biomedical images, but it is now being used for many imaging tasks, such as identifying subcellular features and recovering high-quality images from noisy data. Currently, DL applications are being developed by expert computer scientists who have access to large computing resources required for training these networks. However, the generation and curation of datasets necessary to train the networks have become a new limitation. In the future, the democratization of hardware and software packages will make DL more accessible. However, there are concerns about the biases built into networks due to the curation of training data and catastrophic failures of networks. The field is still undergoing exponential development, and many approaches developed for robotics or computer vision will likely permeate within biomedical research, creating new opportunities for researchers in the life sciences."}, {"heading": "Conclusion", "text": "In \"Unlocking the Potential of Microscopy with Artificial Intelligence: A Comprehensive Guide,\" the authors explore how Deep Learning (DL) based on Artificial Intelligence (AI) is revolutionizing biomedical research and microscopy. DL, a subset of AI, uses neural networks to extract features from large datasets and make predictions or decisions. The paper highlights the applications of DL in image segmentation, classification, and restoration, showcasing its potential to enhance resolution, signal, and information content in microscopy. However, the authors also discuss the limitations and challenges of DL, including biases in training data and the lack of interpretability of network outputs. Despite these challenges, DL has significant implications for biomedical research and microscopy, offering super-human performance in image analysis tasks. The paper calls for the democratization of DL, making it more accessible and reducing the need for large training datasets and expert knowledge. Future research should focus on developing tools to detect network failures and establish trust in AI's role in research. Additionally, integrating AI into microscopy platforms could optimize image acquisition. Overall, DL has the potential to transform the field of microscopy if accessibility barriers are lowered and trust is established."}, {"heading": "References", "text": "@article{lecun2015deep,\n  title={Deep learning},\n  author={Lecun, Y and Bengio, Y and Hinton, G},\n  journal={Nature},\n  year={2015}\n}\n\n@inproceedings{krizhevsky2012imagenet,\n  title={Imagenet classification with deep convolutional neural networks},\n  author={Krizhevsky, B A and Sutskever, I and Hinton, G E},\n  booktitle={Advances in neural information processing systems},\n  year={2012}\n}\n\n@article{rumelhart1986learning,\n  title={Learning representations by back-propagating errors},\n  author={Rumelhart, D E and Hinton, G E and Williams, R J},\n  journal={Nature},\n  year={1986}\n}\n\n@inproceedings{lecun1990handwritten,\n  title={Handwritten digit recognition with a back-propagation network},\n  author={Le Cun, Y and Boser, B and Denker, J S and Howard, R E and Habbard, W and Jackel, L D},\n  booktitle={Advances in neural information processing systems},\n  year={1990}\n}\n\n@article{silver2017mastering,\n  title={Mastering the game of Go without human knowledge},\n  author={Silver, D and Schrittwieser, J and Simonyan, K and Antonoglou, I and Huang, A and Guez, A},\n  journal={Nature},\n  year={2017}\n}\n\n@article{esteva2017dermatologist,\n  title={Dermatologist-level classification of skin cancer with deep neural networks},\n  author={Esteva, A and Kuprel, B and Novoa, R A and Ko, J and Swetter, S M and Blau, H M},\n  journal={Nature},\n  year={2017}\n}\n\n@article{litjens2017survey,\n  title={A survey on deep learning in medical image analysis},\n  author={Litjens, G and Kooi, T and Bejnordi, B E and Setio, A A A and Ciompi, F and Ghafoorian, M},\n  journal={Medical image analysis},\n  year={2017}\n}\n\n@article{roth2018deep,\n  title={Deep learning and its application to medical image segmentation},\n  author={Roth, H R and Shen, C and Oda, H and Oda, M and Hayashi, Y and Misawa, K},\n  journal={Medical Imaging Technology},\n  year={2018}\n}\n\n@article{falk2019u,\n  title={U-Net: deep learning for cell counting, detection, and morphometry},\n  author={Falk, T and Mai, D and Bensch, R and Ci{\\c{c}}ek, {\\\"O} and Abdulkadir, A and Marrakchi, Y},\n  journal={Nature methods},\n  year={2019}\n}\n\n@article{chartrand2017deep,\n  title={Deep learning: a primer for radiologists},\n  author={Chartrand, G and Cheng, P M and Vorontsov, E and Drozdzal, M and Turcotte, S and Pal, C J},\n  journal={Radiographics},\n  year={2017}\n}\n\n@article{lecun1989generalization,\n  title={Generalization and network design strategies},\n  author={Lecun, Y},\n  journal={Connectionist perspectives on learning, development, and conceptual change},\n  pages={143--155},\n  year={1989}\n}\n\n@inproceedings{lecun1989backpropagation,\n  title={Backpropagation applied to handwritten zip code recognition},\n  author={Le Cun, Y and Boser, B and Denker, J S and Henderson, D and Howard, R E and Hubbard, W},\n  booktitle={Neural computation},\n  year={1989}\n}\n\n@inproceedings{maqueda2018event,\n  title={Event-based vision meets deep learning on steering prediction for self-driving cars},\n  author={Maqueda, A I and Loquercio, A and Gallego, G and Garcia, N and Scaramuzza, D},\n  booktitle={Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\n  year={2018}\n}"}]