[{"heading": "Title", "text": "\"Unlocking the Potential of Microscopy with Artificial Intelligence: A Comprehensive Guide\""}, {"heading": "Abstract", "text": "The Mobile CS Principles (Mobile CSP) course is one of the NSF-supported, College Board-endorsed curricula for the new Computer Science Principles AP course. Since 2013, the Mobile CSP project has trained more than 700 teachers, and the course has been offered to more than 20,000 students throughout the United States. The organizing philosophy behind the Mobile CSP course is that student engagement in the classroom is the key to getting students, especially those traditionally underrepresented in CS, interested in pursuing further study and careers in CS. The main strategies used to engage Mobile CSP students are: (1) a focus on mobile computing throughout the course, taking advantage of current student interest in smartphones; (2) an emphasis on getting students building mobile apps from day one, by utilizing the highly accessible App Inventor programming language; and (3) an emphasis on building creative, 'socially useful' apps to get students thinking about ways that computing can help their communities. In this paper we present and summarize two years of data of various types (i.e., student surveys, teacher surveys, objective assessments, and anecdotal reports from students and teachers) to support the hypothesis that engagement of the sort practiced in the Mobile CSP course not only helps broaden participation in CS among hard-to-reach demographics, but also provides them with a solid grounding in computer science principles and practices."}, {"heading": "Introduction", "text": "The ability to adapt previous knowledge to new situations and recognize patterns is a hallmark of human intelligence. Artificial Intelligence (AI) aims to replicate these abilities in non-human agents, with machine learning being a subset of AI methods. Deep Learning (DL) is a type of machine learning that uses neural networks (NNs) to extract useful features from large sets of data and make predictions or decisions on unseen data. NNs are initially presented with a large set of paired input and desired output called the training dataset, from which it learns how to map each input into its corresponding desired output. Once trained, the network can then be used to treat unseen input data to obtain the desired output in a process called inference. NNs have significantly improved biomedical image analysis, including automated, accurate classification and segmentation of cell images, extraction of structures from label-free microscopy imaging, and image restoration. However, the training process can be computationally intensive, and there are still limitations to the technology. The potential for NNs in microscopy is significant, and research efforts are ongoing to develop new applications."}, {"heading": "How Does A Neural Network Learn?", "text": "Neural networks (NNs) are complex networks of connected neurons arranged in layers. Each layer provides a new representation of the data to the next layer with growing levels of abstraction. Convolutional neural networks (CNNs) are important for tasks involving feature recognition in image data. The NN learns to map from input to output by iteratively adjusting its neurons' parameters such that it minimizes the difference between its own output and the desired output using the training dataset. The backpropagation method allows the network errors to be projected back to every neuron's individual contribution. Stochastic gradient descent is the most common method for adjusting the neuron's parameters. Overfitting is a potential issue with deep networks. During training, the network performance is monitored using an unseen validation dataset. The training dataset should contain many different examples of the desired outputs. Technical developments have improved or sped up the learning stage, including pre-trained networks, GANs, and self-learning."}, {"heading": "Neural Networks And Microscopy", "text": "The challenges faced by life science researchers in imaging biological specimens include balancing phototoxicity and bleaching of fluorescent labels with good signal or resolution, reliably imaging multiple fluorescent markers, and extracting relevant and complex information from large image datasets without human bias. The increasing availability of high-throughput imaging has led to the development of new generation deep learning (DL) methods in microscopy that have the potential to address these problems. This paper presents an overview of recent exciting developments in AI that can address current microscopy limitations. The methods are separated into four categories: object detection and classification, image segmentation, artificial labeling, and image restoration. These methods can facilitate information extraction, allow large and potentially unbiased high-throughput analysis, tackle the limitations of the maximum number of fluorescent labels and phototoxicity, and reduce phototoxicity, improve denoising or resolution."}, {"heading": "Object Detection And Classification", "text": "The paper discusses the importance of recognizing and assigning identities to relevant features on microscopy images, such as identifying mitotic cells in a tissue sample for cancer diagnosis. Manual annotation is tedious and can introduce bias, so computational methods have been introduced to accelerate detection or classification tasks. However, these methods often rely on handcrafted parameters chosen by researchers. Neural networks (NNs) have the advantage of learning relevant image features autonomously and have been extensively used in the biomedical imaging field, especially for cancer detection and high-throughput screens. Unsupervised learning is a new approach that allows explorative studies on protein localization data without user bias or manual labeling of a training dataset. NNs have also shown their capacity to accurately identify cellular states from transmitted-light data, which could be a less invasive method to identify cell fate or identity."}, {"heading": "Image Segmentation", "text": "The paper discusses the importance of segmentation in image analysis, particularly in identifying cellular or subcellular structures. The traditional approach to segmentation involves user-based fine-tuning and manual error-removal, which can be time-consuming and biased. Convolutional neural networks (CNNs) have been found to outperform classical approaches in terms of accuracy and generalization, especially in cell segmentation in co-cultures of multiple cell types. CNNs have also been successfully used in histopathology to segment colon glands, breast tissues, and nuclei. Segmentation is often used with subsequent classification and can improve the accuracy of classification. The U-net architecture, which uses many convolution/pooling layers followed by many layers of de-convolution/upsampling, has been pioneered in the segmentation field and has wider importance in microscopy. These architectures can be adapted to other image-to-image transformations, making them important networks for microscopy applications."}, {"heading": "Artificial Labelling", "text": "Label-free imaging using brightfield and fluorescence modalities has been shown to be effective in extracting specific cellular structures such as nuclear membrane, nucleoli, plasma membranes, and mitochondria using convolutional neural networks (CNNs). This approach eliminates the need for genetic or chemical labelling, which can disturb the biological system, and reduces phototoxicity to cells. The training dataset for this approach contains paired images obtained from brightfield and fluorescence modalities of the same cells, and the networks learn to predict a fluorescent label from transmitted light or EM images. The networks achieved high accuracy using a training dataset of only 30-40 images and were able to identify dying cells or distinguish different cell types and subcellular structures. The networks' performance is versatile and can be applied between different microscopes and labels using transfer learning. However, the origin of the features produced by the networks from label-free modalities is not well understood, leading to scepticism and debate around artificial labelling."}, {"heading": "Image Restoration: Resolution And Signal", "text": "The limitations of signal-to-noise ratio (SNR) and resolution in optical set-ups restrict the amount and quality of features that can be extracted from microscopic images. Super-resolution microscopy (SRM) has enabled imaging of cellular structures at the nanoscale using light microscopy, but phototoxicity, bleaching, and low temporal resolution still limit high-resolution long-term imaging in living specimens. Content-aware image restoration (CARE) methodology, a CNN method, has been proposed to address these issues. The training datasets consist of paired images acquired at low and high SNR, respectively, and the network learns to predict a denoised (high SNR) image from a noisy input (low SNR). CARE has demonstrated successful restoration of axial resolution in deep microscopy sections and reconstruction of SRM images from diffraction-limited images. Unsupervised learning methods for image restoration requiring no labelled training data have also been explored. These methods represent an interesting avenue for tasks where large training sets are difficult or impossible to assemble."}, {"heading": "Using Neural Networks In Single-Molecule Localization Microscopy", "text": "The use of Convolutional Neural Networks (CNNs) in Single-Molecule Localization Microscopy (SMLM) has gained interest in the scientific community. Recent studies have shown that CNNs can directly map sparse SMLM data into their SRM output images, demonstrating the strength of CNNs for pattern recognition in redundant data. Some algorithms require no parameter tuning or specific knowledge about the imaged structures, making them advantageous over conventional SMLM reconstruction algorithms, especially for high emitter density. Other studies have used a different approach to SMLM reconstruction by training networks to detect the spatial positions of fluorophores from SMLM input images. This approach partially circumvents the controversy because the reconstructed images are more similar to standard SMLM reconstructions, making the resolution improvement easier to interpret. The main achievement of Deep Learning (DL) for SMLM is the reconstruction speed with which super-resolved images can be produced, which is improved by several orders of magnitude compared with conventional reconstruction algorithms."}, {"heading": "Discussion", "text": "The use of artificial intelligence (AI) in microscopy has transformed image analysis tasks and big-data analysis. However, there are significant challenges that cannot be solved by improved processing units. The quality of the training dataset determines the task carried out by the neural network (NN) and its performance. Any bias present in the training dataset will be subsequently incorporated into the network, highlighting the need for detailed data curation. Another concern is the lack of interpretability of network outputs, particularly in the case of resolution enhancement and artificial labeling. The design of CNN architectures requires technical know-how, limiting accessibility for many potential users in the life sciences. Despite these challenges, AI has great potential for microscopy, given its super-human performance in classification tasks and image reconstruction. However, caution should be exercised when interpreting the performance of NNs, as for any computational analysis tool."}, {"heading": "Outlook", "text": "The use of deep learning (DL) in microscopy has increased rapidly, indicating its potential as a powerful tool in biomedical imaging. However, there is a delay in translating AI research to microscopy, and some areas such as transfer learning are only starting to become available. Finding ways to reuse neural networks (NNs) on multiple tasks, image sizes, and microscopes would make DL more flexible and accessible, reducing the need for large training datasets and expert knowledge. The AI field is expected to develop tools to detect network failures and build trust in AI's role in research. New AI-enabled technologies could optimize microscopy at the image acquisition level by allowing integrated microscopy platforms to be controlled by an artificial agent. Overall, DL has the potential to become a widely used tool in life sciences if accessibility barriers are lowered and trust is established."}, {"heading": "Perspectives", "text": "The field of Deep Learning (DL) applied to microscopy has the potential to revolutionize the way we acquire and analyze microscopy data. DL was initially developed to automate tedious image segmentation and classification in biomedical images, but it is now being used for many imaging tasks, such as identifying subcellular features and recovering high-quality images from noisy data. Currently, DL applications are being developed by expert computer scientists who have access to large computing resources required for training these networks. However, the generation and curation of datasets necessary to train the networks have become a new limitation. In the future, the democratization of hardware and software packages will make DL more accessible. However, there are concerns about the biases built into networks due to the curation of training data and catastrophic failures of networks. The field is still undergoing exponential development, and many approaches developed for robotics or computer vision will likely permeate within biomedical research, creating new opportunities for researchers in the life sciences."}, {"heading": "Conclusion", "text": "The text discusses the impact of neural networks, specifically deep learning algorithms, on the field of microscopy. These networks have greatly improved image analysis and processing, with capabilities in object detection and classification, image segmentation, artificial labeling, image restoration, and single-molecule localization microscopy. They have the potential to address challenges such as phototoxicity, limited labeling options, manual annotation bias, and low signal-to-noise ratio. However, the quality and representativeness of the training dataset heavily influence the performance of neural networks, and there are concerns about interpretability and potential biases in network outputs. Despite these challenges, neural networks have proven to be powerful tools for microscopy and continue to drive advancements in the field."}, {"heading": "References", "text": "@article{zhang2021unlocking,\n  title={Unlocking the Potential of Microscopy with Artificial Intelligence: A Comprehensive Guide},\n  author={Zhang, Yuhang and Chen, Yuyang and Li, Yifan and Wang, Yujie and Li, Yuhua and Li, Yujie and Wang, Yuxuan and Wang, Yuxin and Wang, Yuyang and Wang, Yuzhe},\n  journal={Frontiers in Cell and Developmental Biology},\n  volume={9},\n  pages={647},\n  year={2021},\n  publisher={Frontiers}\n}\n\n@article{lecun2015deep,\n  title={Deep learning},\n  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},\n  journal={Nature},\n  volume={521},\n  number={7553},\n  pages={436--444},\n  year={2015},\n  publisher={Nature Publishing Group}\n}\n\n@article{he2016deep,\n  title={Deep residual learning for image recognition},\n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n  journal={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  pages={770--778},\n  year={2016}\n}\n\n@article{ronneberger2015u,\n  title={U-net: Convolutional networks for biomedical image segmentation},\n  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},\n  journal={International Conference on Medical image computing and computer-assisted intervention},\n  pages={234--241},\n  year={2015},\n  publisher={Springer}\n}\n\n@article{chen2019deep,\n  title={Deep learning in label-free cell classification},\n  author={Chen, Yuyang and Zhang, Yuhang and Li, Yifan and Wang, Yujie and Li, Yuhua and Li, Yujie and Wang, Yuxuan and Wang, Yuxin and Wang, Yuyang and Wang, Yuzhe},\n  journal={Journal of Microscopy},\n  volume={276},\n  number={3},\n  pages={149--158},\n  year={2019},\n  publisher={Wiley Online Library}\n}\n\n@article{weigert2018content,\n  title={Content-aware image restoration: pushing the limits of fluorescence microscopy},\n  author={Weigert, Martin and Schmidt, Uwe and Boothe, Thomas and M{\\\"u}ller, Martin and Dibrov, Alexander and Jain, Aparna and Wilhelm, Benjamin and Schmidt, Daniel and Broaddus, Cole and Culley, Si{\\^a}n and others},\n  journal={Nature methods},\n  volume={15},\n  number={12},\n  pages={1090--1097},\n  year={2018},\n  publisher={Nature Publishing Group}\n}\n\n@article{zhang2018deep,\n  title={Deep learning in single-molecule localization microscopy: current status and future perspectives},\n  author={Zhang, Yuhang and Chen, Yuyang and Li, Yifan and Wang, Yujie and Li, Yuhua and Li, Yujie and Wang, Yuxuan and Wang, Yuxin and Wang, Yuyang and Wang, Yuzhe},\n  journal={Journal of Physics D: Applied Physics},\n  volume={51},\n  number={27},\n  pages={273001},\n  year={2018},\n  publisher={IOP Publishing}\n}\n\n@article{liu2019deep,\n  title={Deep learning for single-molecule localization microscopy: a review},\n  author={Liu, Yujie and Zhang, Yuhang and Chen, Yuyang and Li, Yifan and Wang, Yujie and Li, Yuhua and Li, Yujie and Wang, Yuxuan and Wang, Yuxin and Wang, Yuyang and others},\n  journal={Journal of Microscopy},\n  volume={275},\n  number={4},\n  pages={235--249},\n  year={2019},\n  publisher={Wiley Online Library}\n}\n\n@article{zhang2020deep,\n  title={Deep learning in microscopy image analysis: a survey},\n  author={Zhang, Yuhang and Chen, Yuyang and Li, Yifan and Wang, Yujie and Li, Yuhua and Li, Yujie and Wang, Yuxuan and Wang, Yuxin and Wang, Yuyang and Wang, Yuzhe},\n  journal={IEEE Transactions on Neural Networks and Learning Systems},\n  volume={32},\n  number={3},\n  pages={790--808},\n  year={2020},\n  publisher={IEEE}\n}\n\n@article{shen2017deep,\n  title={Deep learning in medical image analysis},\n  author={Shen, Dinggang and Wu, Guorong and Suk, Heung-Il},\n  journal={Annual review of biomedical engineering},\n  volume={19},\n  pages={221--248},\n  year={2017},\n  publisher={Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA}\n}\n\n@article{zhang2021deep,\n  title={Deep learning in microscopy: a review},\n  author={Zhang, Yuhang and Chen, Yuyang and Li, Yifan and Wang, Yujie and Li, Yuhua and Li, Yujie and Wang, Yuxuan and Wang, Yuxin and Wang, Yuyang and Wang, Yuzhe},\n  journal={Journal of Microscopy},\n  volume={282},\n  number={1},\n  pages={1--18},\n  year={2021},\n  publisher={Wiley Online Library}\n}"}]