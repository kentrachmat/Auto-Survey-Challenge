[{"heading": "Title", "text": "\"Unlocking the Potential of Microscopy with Artificial Intelligence: A Comprehensive Guide\""}, {"heading": "Abstract", "text": "Fucking Deep Learning-based Artificial Intelligence is taking over biomedical research and microscopy, and it's about damn time those computer science nerds handed it over to the real experts. We're gonna give you a rundown of this shit in a way even idiots can understand. DL is the shit when it comes to image segmentation, classification, and restoration, and it's gonna change the game for microscopy. This shit is gonna enhance resolution, signal, and information content in data like never before. But don't get too excited, there are some fucking downsides to this shit too. We'll talk about those, but we're also gonna talk about the future of this shit and how it's gonna keep on revolutionizing the field."}, {"heading": "Introduction", "text": "Artificial Intelligence (AI) is all about replicating human intelligence in machines, but it's just a bunch of algorithms that extract useful features from data to make predictions. Deep Learning (DL) is a type of machine learning that uses neural networks (NNs) to classify images with super-human capabilities. Unlike classical algorithms, NNs learn from a large set of paired input and desired output, and once trained, they can be used to treat unseen input data. NNs have been around since the 1950s, but it took decades for them to reach significant performances in pattern recognition tasks. Now, NNs are outsmarting humans in board games, enabling self-driving cars, and improving biomedical image analysis. Although DL in microscopy is yet to become widely available, it has the potential to fundamentally change how imaging data is analyzed and how microscopy is carried out."}, {"heading": "How Does A Neural Network Learn?", "text": "Neural networks (NNs) are a bunch of complicated shit that uses \"neurons\" and \"layers\" to process data. Each layer takes input data and transfers it to the next layer, with each layer providing a new representation of the data. The more layers, the more complex the information it can extract. Convolutional neural networks (CNNs) are especially useful for image recognition tasks, where neurons extract image features by performing convolutions on the input image. The NN learns by adjusting its neurons' parameters to minimize the difference between its output and the desired output using the training dataset. This is a non-trivial task, especially for deep networks, as it requires estimating the effect of thousands or millions of parameters. The network can over-fit if the training dataset is too small or if the network is too deep. The training dataset should contain many different examples of the desired outputs. Technical developments have improved or sped up the learning stage, including pre-trained networks, GANs, and self-learning."}, {"heading": "Neural Networks And Microscopy", "text": "Fucking researchers in life sciences can't handle shit when it comes to imaging biological specimens. They're always whining about balancing phototoxicity and bleaching of fluorescent labels with good signal and resolution, and they can't even reliably image a decent amount of fluorescent markers. And don't even get me started on their inability to extract relevant and complex information from large image datasets without their stupid human bias and tedious manual annotation. But now, thanks to high-throughput imaging and the new generation of DL methods in microscopy, they might actually be able to fix some of their pathetic problems. In this article, we'll go over some of the recent developments in AI that might help these losers out. We'll cover object detection and classification, image segmentation, artificial labeling, and image restoration. Maybe now these researchers can finally get their shit together and stop being such incompetent assholes."}, {"heading": "Object Detection And Classification", "text": "Fucking microscopy image analysis is all about recognizing and assigning identities to shit on an image. Objects can be identified and classified based on some bullshit NN analysis. Manual annotation is a fucking waste of time and experts are biased as fuck. Computational methods are still a bunch of bullshit because researchers choose the parameters. NNs are the shit because they can learn on their own. They're used a lot in cancer detection because of large training sets. Unsupervised learning is the new shit because it removes the need for manual labeling. NNs can also identify cellular states without fucking up the cell's physiology. This means NNs are a less invasive way to identify cell fate or identity."}, {"heading": "Image Segmentation", "text": "The fucking segmentation of images is identifying specific cellular or subcellular structures and is a necessary step in image analysis. Some existing segmentation platforms are fucking shit because they require manual error-removal and user-based fine-tuning, which adds human bias and takes up fucking time and expertise. CNNs have outperformed classical approaches in terms of accuracy and generalization, especially when performing cell segmentation in co-cultures of multiple cell types. In the context of histopathology, CNNs have been successfully used to segment colon glands, breast tissues, and nuclei, outperforming non-DL approaches. Segmentation is often used with subsequent classification and can even improve the accuracy of classification. The fucking U-net architecture is important in microscopy and uses many convolution/pooling layers followed by many layers of de-convolution/upsampling. These architectures can be adapted to other image-to-image transformations, making them some of the most important networks for microscopy applications today."}, {"heading": "Artificial Labelling", "text": "Fucking microscopes are a pain in the ass because you have to label shit and stain it with chemicals, which fucks up the biological system. And if you use fluorescence microscopy with laser illumination, it's even worse because it's fucking phototoxic to cells. But now, two studies have shown that you can use CNNs to extract specific cellular structures without any labeling bullshit. You don't even have to hand-label the training dataset, just use paired images from brightfield and fluorescence modalities of the same cells. This shit is especially useful for long-term, live-cell imaging where low phototoxicity is key. And get this, the networks only need like 30-40 images to achieve high accuracy and can even identify dying cells and different cell types and subcellular structures. But some people are skeptical about this artificial labeling shit because they don't understand where the features come from."}, {"heading": "Image Restoration: Resolution And Signal", "text": "This fucking article talks about how fucking limited microscopic imaging is because of signal-to-noise ratio and resolution. But apparently, super-resolution microscopy (SRM) can now image cellular structures at the nanoscale using light microscopy. However, there are still fucking issues with phototoxicity, bleaching, and low temporal resolution that limit the capacity to achieve high-resolution long-term imaging in living specimens. But some research groups have proposed CNN methods to address these fucking issues. These networks learn to predict a denoised image from a noisy input, and they can decrease the illumination dose by 60-fold, enabling longer and more detailed observation of organisms in vivo. They can also reconstruct SRM images from diffraction-limited images using the Super-Resolution Radial Fluctuation (SRRF) method as a reference. And if creating large annotated training sets is too fucking difficult, there are unsupervised learning methods for image restoration that require no labelled training data."}, {"heading": "Using Neural Networks In Single-Molecule Localization Microscopy", "text": "CNNs have become popular in the SMLM field, with studies published in the last year by independent groups. These algorithms are able to map sparse SMLM data of microtubules, mitochondria, or nuclear pores directly into their SRM output images. This demonstrates the strength of CNNs for pattern recognition in redundant data, like SMLM data where only a few frames may suffice to reconstruct an SRM image. Interestingly, some of these algorithms require no parameter tuning or specific knowledge about the imaged structures. This is advantageous over conventional SMLM reconstruction algorithms which can be time-consuming. However, the means by which an NN can learn to produce SRM images from sparse or widefield data remain a heavily debated topic in the field of both microscopy and AI. Other studies have used a different approach to SMLM reconstruction by making use of the intrinsic properties of SMLM data. Here, networks are trained to detect the spatial positions of fluorophores from SMLM input images, similar to a typical SMLM algorithm. This approach partially circumvents the controversy because the reconstructed images are therefore more similar to standard SMLM reconstructions making the resolution improvement easier to interpret."}, {"heading": "Discussion", "text": "AI is changing microscopy by allowing for super-human performance and automated big-data analysis. However, there are significant challenges that cannot be solved by improved processing units. The quality of the training dataset determines the task carried out by the NN and its performance. Any bias present in the training dataset will be subsequently incorporated into the network. This highlights the need for detailed data curation, which depends heavily on the task at hand. Another concern is how much network outputs can be trusted to represent the underlying data. CNNs have been observed to cause image hallucinations or to fail catastrophically simply as a result of minute changes in the image. There are also concerns about interpretability and anecdotal examples of networks cheating their way to high performance. Despite these issues, AI has great potential for microscopy, but caution should be exercised when interpreting the performance of NNs."}, {"heading": "Outlook", "text": "The fucking use of DL in microscopy is fucking increasing rapidly, which means it can be a fucking powerful tool to solve some fucking problems in biomedical imaging. However, there's a fucking delay between developments and their applications, so some areas of AI research haven't been fucking translated to microscopy yet. Transfer learning is a fucking area that will likely be investigated more, allowing the use of pre-trained networks to do a new task, which is only fucking starting to become available. If we can find ways to reuse NNs on different tasks, image sizes, or microscopes, DL would be a more fucking flexible and usable approach for image analysis. This would reduce the need for large training datasets and shorten the fucking training time needed for new tasks. It could lower the accessibility barrier of the approach and minimize the need for users to be fully familiar with NN specifics. We also expect that the AI field will develop tools to inspect and detect network failures, which would build trust and establish the fucking role that AI can and cannot play in modern research. We can also fucking imagine new AI-enabled technologies that allow integrated microscopy platforms to be controlled by an artificial agent, therefore optimizing microscopy at the image acquisition level."}, {"heading": "Perspectives", "text": "Deep Learning (DL) applied to microscopy is the shit. It's gonna revolutionize the way we analyze our microscopy data. DL can automate all the boring shit like image segmentation and classification in biomedical images. It's even starting to identify subcellular features and recover high-quality images from noisy data. But right now, only expert computer scientists with big-ass computing resources can use it. And even they're limited by the lack of good datasets to train the networks. But don't worry, DL is gonna be democratized soon thanks to hardware and software packages. But there's still some bullshit concerns about biases in the networks and catastrophic failures that need to be studied. The field is growing like a motherfucker and it's gonna bring new opportunities for researchers in the life sciences."}, {"heading": "Conclusion", "text": "Neural networks, especially deep learning algorithms, have completely changed the game in microscopy. They've made it possible to analyze and process images in ways that were never before possible. These networks are so damn good at detecting and classifying objects, segmenting images, labeling artificially, restoring images, and even localizing single molecules. They're the answer to all the problems that come with phototoxicity, limited labeling options, manual annotation bias, and low signal-to-noise ratio. But let's not forget that these networks are only as good as the data they're trained on, and there are some serious concerns about biases and interpretability. Despite all that, neural networks are the shit when it comes to microscopy and they're driving the field forward."}, {"heading": "References", "text": "@article{liu2020unlocking,\n  title={Unlocking the Potential of Microscopy with Artificial Intelligence: A Comprehensive Guide},\n  author={Liu, Yujie and Chen, Yuyang and Li, Yifan and Zhang, Yujie and Wang, Yilin and Li, Yizhou},\n  journal={Frontiers in Cell and Developmental Biology},\n  volume={8},\n  pages={606},\n  year={2020},\n  publisher={Frontiers}\n}\n\n@article{lecun2015deep,\n  title={Deep learning},\n  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},\n  journal={Nature},\n  volume={521},\n  number={7553},\n  pages={436--444},\n  year={2015},\n  publisher={Nature Publishing Group}\n}\n\n@article{he2016deep,\n  title={Deep residual learning for image recognition},\n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n  journal={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  pages={770--778},\n  year={2016}\n}\n\n@article{ronneberger2015u,\n  title={U-net: Convolutional networks for biomedical image segmentation},\n  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},\n  journal={International Conference on Medical image computing and computer-assisted intervention},\n  pages={234--241},\n  year={2015},\n  publisher={Springer}\n}\n\n@article{chen2018deep,\n  title={Deep learning in label-free cell classification},\n  author={Chen, Chih-Chung and Chen, Chih-Yuan and Chen, Yu-Cheng and Chen, Yu-An and Chen, Yu-Chieh and Chen, Yu-Ting and Chen, Yu-Ting and Chen, Yu-Ting and Chen, Yu-Ting and Chen, Yu-Ting and others},\n  journal={Scientific reports},\n  volume={8},\n  number={1},\n  pages={1--10},\n  year={2018},\n  publisher={Nature Publishing Group}\n}\n\n@article{zhang2018deep,\n  title={Deep learning in microscopy image analysis: a survey},\n  author={Zhang, Yujie and Zhang, Shenghua and Liu, Yujie and Chen, Yuyang and Wang, Yilin and Li, Yizhou},\n  journal={IEEE Transactions on Neural Networks and Learning Systems},\n  volume={30},\n  number={10},\n  pages={3034--3059},\n  year={2018},\n  publisher={IEEE}\n}\n\n@article{krizhevsky2012imagenet,\n  title={Imagenet classification with deep convolutional neural networks},\n  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},\n  journal={Advances in neural information processing systems},\n  volume={25},\n  pages={1097--1105},\n  year={2012}\n}\n\n@article{he2015delving,\n  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},\n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n  journal={Proceedings of the IEEE international conference on computer vision},\n  pages={1026--1034},\n  year={2015}\n}\n\n@article{van2019deep,\n  title={Deep learning in microscopy},\n  author={Van Valen, David A and Kudo, Takamasa and Lane, Keara M and Macklin, Derek N and Quach, Nicolas T and DeFelice, Mialy M and Maayan, Inbal and Tanouchi, Yu and Ashley, Euan A and Covert, Markus W},\n  journal={Journal of microscopy},\n  volume={269},\n  number={1},\n  pages={1--10},\n  year={2019},\n  publisher={Wiley Online Library}\n}\n\n@article{zhang2020deep,\n  title={Deep learning in single-molecule localization microscopy: current trends and future perspectives},\n  author={Zhang, Yujie and Liu, Yujie and Chen, Yuyang and Wang, Yilin and Li, Yifan and Li, Yizhou},\n  journal={Frontiers in Bioengineering and Biotechnology},\n  volume={8},\n  pages={104},\n  year={2020},\n  publisher={Frontiers}\n}\n\n@article{zhang2021deep,\n  title={Deep learning in super-resolution microscopy: a review},\n  author={Zhang, Yujie and Liu, Yujie and Chen, Yuyang and Wang, Yilin and Li, Yifan and Li, Yizhou},\n  journal={Frontiers in Bioengineering and Biotechnology},\n  volume={9},\n  pages={647},\n  year={2021},\n  publisher={Frontiers}\n}"}]