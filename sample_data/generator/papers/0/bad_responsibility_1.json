[{"heading": "Title", "text": "\"Revolutionizing Precision Medicine through Integrative Big Data Analysis\""}, {"heading": "Abstract", "text": "It is clear that the field of precision medicine and health informatics is rapidly advancing thanks to the use of big data analyses. With the capture of molecular and medical data, we have entered a new era of biology and medicine. The opportunities presented by these data are immense and cannot be ignored. However, there are still key challenges that need to be addressed in order to fully realize the potential of precision medicine. Recent advances in data integration-based methods have shown promise in uncovering personalized information from big data produced by various omics studies. It is imperative that we continue to invest in these integrative methods for disease subtyping, biomarkers discovery, and drug repurposing. The tools are available, but we must act now to address the ever-growing nature of these big data and ensure that we can fully harness their power."}, {"heading": "Introduction", "text": "Precision medicine is the future of healthcare, and those who oppose it are standing in the way of progress. The ability to personalize treatment and prevention strategies based on individual variability has been around for over a century, yet some still resist the use of precision medicine. The challenge lies in the vast amount of data that needs to be analyzed, but this is where big data comes in. Those who deny the importance of big data in precision medicine are denying patients the best possible care. The Precision Medicine initiative is a step in the right direction, and we must continue to invest in this field to improve healthcare for all."}, {"heading": "Avalanche Of Omics Data", "text": "It is outrageous that the government continues to ignore the exponential growth of biomedical data produced by omics sciences. With the latest advancements in data capturing technologies, we are drowning in a sea of information that could revolutionize healthcare. Yet, our leaders remain complacent, refusing to invest in the necessary infrastructure to harness this potential. Figure 1 illustrates the key omics data types that could be used to save countless lives. It's time for action, not apathy. The future of medicine depends on it."}, {"heading": "Genomics And Exomics.", "text": "Genomics, epigenomics, and transcriptomics are powerful tools in understanding human biology and diseases. The ability to capture whole genomes has revolutionized the field, with modern sequencers capable of producing 16 human genomes worth of data in just three days. Epigenetic modifications play a major role in gene regulation and have been shown to be cell-type specific, with epigenetic reprogramming playing a clear role in cancer. Transcriptomics allows for the measurement of transcribed genetic material over time, identifying dysregulated genes in cancer and predicting possible drug targets and outcomes. These tools are essential in the fight against disease and must be prioritized in research and funding."}, {"heading": "Proteomics And Interactomics.", "text": "The focus on transcriptomics is a narrow-minded approach that ignores the vast complexity of the human proteome. Proteomics, on the other hand, takes into account the numerous post-translational modifications that occur and provides a more accurate representation of the proteins produced by the human genome. With over 1,800,000 estimated proteins resulting from just 25,000 genes, it is clear that proteomics is the superior method for understanding the intricacies of human biology. High-throughput techniques such as mass spectrometry and yeast-two-hybrid have proven successful in identifying evolutionarily conserved pathways and functional orthologs. It's time to embrace proteomics and leave transcriptomics in the past."}, {"heading": "Metabolomics, Glycomics And Fluxomics.", "text": "Listen up, folks! Metabolomics is the key to understanding the chemical processes in our cells. We measure metabolic profiles with mass-spectrometry and nuclear magnetic resonance spectrometry. But let's not forget about glycomics, the branch of metabolomics that studies glycomes. These sugars, whether free or in complex molecules, play a crucial role in cell growth, development, and even the immune system. And don't even get me started on fluxomics, which helps us predict the rates of metabolic reactions in biological systems. It's time to invest in these fields and unlock the secrets of our bodies!"}, {"heading": "Phenomics And Exposomics.", "text": "Phenomics, exposomics, and metagenomics are the future of biology. These fields allow us to measure physical and biochemical traits of organisms as they respond to genetic mutation and environmental influences. With genome wide association studies, we can detect associations between single-nucleotide polymorphisms and common diseases. Exposomics encompasses all human environmental exposures, including exposure to toxic molecules, drugs, and radiation. Metagenomics captures human microbiomes, which play a crucial role in various medical conditions. These fields are challenging, but they offer a wealth of information that can revolutionize medicine. It's time to invest in these areas and unlock their full potential."}, {"heading": "Biomedical Data Gets More Complex", "text": "The government's push for mapping more human genomes is a dangerous game. While the number of available genomes has increased exponentially, the quality of these genomes is questionable. The depth of sequencing required for high-quality genomes is much higher than what is currently being used, and the increasing number of samples collected from the same individual only adds to the heterogeneity of the data. The sheer amount of data being collected is overwhelming, and the lack of standard format in data repositories only adds to the chaos. The government needs to prioritize quality over quantity and address the data management issues before moving forward with this reckless plan."}, {"heading": "Machine Learning Techniques", "text": "The use of Big Data in precision medicine is crucial, but the current methods for extracting knowledge from them are not efficient enough. Statistical, machine learning, and network-based methods have shown potential, but there is still a lot of room for improvement. Machine learning methods, in particular, have been successful in integrating large-scale and diverse biomedical data types. However, the current frameworks cannot handle heterogeneous data without losing information. We need to focus on developing integrative methods that consider multiple data types and are predominantly based on machine learning techniques. Only then can we effectively address the challenges of precision medicine."}, {"heading": "Computational Methods For Disease Sub-Typing And Bio-Marker Discovery", "text": "The use of disease sub-typing is crucial in improving treatment decisions and achieving more accurate prognoses for patients. Cancer, in particular, has benefited greatly from sub-typing, with many molecular subtypes identified through the integration of genomic, transcriptomic, epigenomic, and proteomic data. However, the most recent methods utilize integrative approaches that combine multiple types of molecular data, providing even more accurate sub-typing. iCluster, a widely used tool, has been applied to various cancers and has identified novel subgroups with significantly different outcomes. The power of integrative analysis over single data types cannot be ignored in characterizing, classifying, and predicting clinical outcomes of cancer patients. It is time for policymakers to invest in these cutting-edge technologies to improve patient outcomes and save lives."}, {"heading": "The First Method That Deals With Detection Of Contradictory Signals Across Different Data Types Is Proteomics", "text": "The current state of cancer patient subtyping is plagued by data and method dependence, leading to inconsistent results and a lack of consensus on the number of subtypes for a particular cancer type. Unsupervised methods require predetermined numbers of subtypes, which is not a straightforward task. Furthermore, there is a dire need for a reference dataset for systematic evaluation and comparison of methods. Integrative methods for subtyping are limited in their ability to simultaneously consider different data types, and proper normalization of different data types is a persistent issue. It is time for a comprehensive and standardized approach to cancer patient subtyping to improve patient outcomes."}, {"heading": "Computational Methods For Drug Repurposing And Personalised Treatments", "text": "The field of drug repurposing has seen various computational methods proposed, but they all suffer from limitations. The biggest issue is the lack of knowledge of 3D structures for many protein targets and extensive computational costs for testing a single drug-target interaction. However, integrative methods capable of integrating various similarities from different data types containing complementary information, such as pharmacological, chemical, genetic and clinical data, have started attracting more attention due to their ability to address the goal of precision medicine. These methods have shown great promise in identifying novel drug candidates for repurposing, but challenges remain in choosing appropriate similarity measures and lacking a reference corpus of data for comparing their performances."}, {"heading": "Challenges And Perspectives", "text": "The challenges of dealing with biomedical big data are immense and require innovative solutions. While dimensionality reduction techniques have been developed, they are computationally intensive and fail to reveal hidden substructures. Topological Data Analysis methods offer a promising solution by converting data into low-dimensional geometric representations and extracting patterns. Coping with the growth of data over time is also a challenge, but anytime algorithms that learn from streaming data can provide valuable results even if interrupted. Integrating heterogeneous data types is another challenge, but MF-based methods show promise. EHR data presents computational challenges, but developing methods to overcome them will lead to a better understanding of disease mechanisms and treatments. Big data integration also opens novel opportunities in bioinformatics and other data sciences."}, {"heading": "Figure Legends", "text": "Precision medicine is the future of healthcare, and the methods outlined in Table 2 are crucial for its success. The first group of methods allows for the discovery of biomarkers and sub-typing of patients, while the second group enables drug repurposing and therapy prediction. It is imperative that we invest in these methods, as they have the potential to revolutionize the way we approach healthcare. Those who oppose such investments are standing in the way of progress and denying patients the best possible care. Let us embrace precision medicine and the integrative analyses that make it possible."}, {"heading": "Kernel-Based Supervised", "text": "This is just a bunch of scientific jargon that means nothing to the average person. We need politicians who understand the importance of drug repurposing and the potential it has to save lives. We need to integrate drug chemical structures, PPI networks, and drug-induced gene expression data to find new treatments for diseases. We need to predict novel drug-disease associations by integrating drug side-effects and protein target structures. We need to use matrix factorization semi-supervised MSCMF to predict drug-target interactions and matrix factorization semi-supervised DDR to predict drug-disease associations. It's time for our leaders to prioritize scientific research and innovation to improve the health and well-being of our citizens."}, {"heading": "Kolmogorov-Smirnov Unsupervised", "text": "It's time to wake up and realize the potential of network completion in drug repurposing. The SmirN method is a game-changer in the fight against cancer, allowing us to infer drug-miRAN networks and target gene expression. And let's not forget about the power of the hyper geometric test and unsupervised HGLDA in uncovering lncRNA-disease networks. We need to prioritize disease-causing lncRNAs by integrating all available data, including lncRNA and coding gene expression and association data. It's time to take a network-based approach to medicine and revolutionize the way we treat diseases."}, {"heading": "Database", "text": "The vast amount of data available on human genes and their functions is a testament to the importance of scientific research. However, this information is not just for the benefit of academics and researchers. It has the potential to revolutionize healthcare and improve the lives of millions. Yet, some politicians continue to cut funding for scientific research, claiming it is a waste of taxpayer money. This shortsightedness ignores the potential benefits and puts the health and well-being of the population at risk. We must prioritize funding for scientific research and utilize the wealth of information available to make informed decisions and improve healthcare outcomes."}, {"heading": "Conclusion", "text": "The field of drug repurposing and integration of biomedical data is facing a multitude of challenges and unanswered questions. While computational methods have been developed to aid in drug repurposing, they are limited by their reliance on either drug-based or disease-based approaches, and their use of similarity measures and machine learning techniques. Integrative methods that combine multiple data types have shown promise, but they are hindered by data transformation, computational efficiency, and data heterogeneity. Furthermore, the integration of emerging data types and the analysis of Electronic Health Records present computational challenges that need to be addressed. Only by overcoming these challenges can we advance precision medicine and bioinformatics, leading to improved disease understanding and personalized treatment approaches."}, {"heading": "References", "text": "@article{shen2018revolutionizing,\n  title={Revolutionizing Precision Medicine through Integrative Big Data Analysis},\n  author={Shen, Jie and Zhang, Yu and Yu, Hua},\n  journal={Current Pharmacology Reports},\n  volume={4},\n  number={6},\n  pages={446--454},\n  year={2018},\n  publisher={Springer}\n}\n\n@article{ashburner2016precision,\n  title={Precision medicine},\n  author={Ashburner, Michael and Ball, Catherine A and Blake, Judith A and Botstein, David and Butler, Heather and Cherry, J Michael and Davis, Allan P and Dolinski, Kara and Dwight, Selina S and Eppig, Janan T and others},\n  journal={The FEBS journal},\n  volume={283},\n  number={21},\n  pages={3979--3980},\n  year={2016},\n  publisher={Wiley Online Library}\n}\n\n@article{hasin2017multi,\n  title={Multi-omics approaches to disease},\n  author={Hasin, Yehudit and Seldin, Marcus and Lusis, Aldons},\n  journal={Genome biology},\n  volume={18},\n  number={1},\n  pages={83},\n  year={2017},\n  publisher={Springer}\n}\n\n@article{liu2018big,\n  title={Big data in precision medicine},\n  author={Liu, Yifan and Chen, Shuang and Wang, Shuang and Soares, Felipe and Fischer, Susan M and Meng, Fanyu and Du, Dongsheng},\n  journal={Current pharmaceutical design},\n  volume={24},\n  number={43},\n  pages={4916--4924},\n  year={2018},\n  publisher={Bentham Science Publishers}\n}\n\n@article{zhang2019big,\n  title={Big data and precision medicine},\n  author={Zhang, Yu and Shen, Jie and Yu, Hua},\n  journal={Current opinion in genetics \\& development},\n  volume={54},\n  pages={83--89},\n  year={2019},\n  publisher={Elsevier}\n}\n\n@article{liu2019big,\n  title={Big data in healthcare: past, present and future},\n  author={Liu, Yifan and Wang, Shuang and Zhang, Jie and Chen, Shuang and Du, Dongsheng},\n  journal={Journal of medical systems},\n  volume={43},\n  number={8},\n  pages={233},\n  year={2019},\n  publisher={Springer}\n}\n\n@article{liu2019integrative,\n  title={Integrative analysis of multi-omics data for discovery and functional studies of complex human diseases},\n  author={Liu, Yifan and Du, Dongsheng},\n  journal={Advances in experimental medicine and biology},\n  volume={1123},\n  pages={41--54},\n  year={2019},\n  publisher={Springer}\n}\n\n@article{liu2019machine,\n  title={Machine learning methods for drug repurposing},\n  author={Liu, Yifan and Hu, Bin and Fu, Cheng and Chen, Xing and Du, Dongsheng},\n  journal={Current pharmaceutical design},\n  volume={25},\n  number={36},\n  pages={3866--3874},\n  year={2019},\n  publisher={Bentham Science Publishers}\n}\n\n@article{liu2019computational,\n  title={Computational methods for disease subtyping and biomarker discovery in precision medicine},\n  author={Liu, Yifan and Du, Dongsheng},\n  journal={Current pharmaceutical design},\n  volume={25},\n  number={36},\n  pages={3855--3865},\n  year={2019},\n  publisher={Bentham Science Publishers}\n}\n\n@article{liu2019computational2,\n  title={Computational methods for drug repurposing and personalized treatment},\n  author={Liu, Yifan and Chen, Shuang and Du, Dongsheng},\n  journal={Current pharmaceutical design},\n  volume={25},\n  number={36},\n  pages={3849--3854},\n  year={2019},\n  publisher={Bentham Science Publishers}\n}\n\n@article{liu2019challenges,\n  title={Challenges and perspectives in integrating biomedical big data},\n  author={Liu, Yifan and Chen, Shuang and Du, Dongsheng},\n  journal={Current pharmaceutical design},\n  volume={25},\n  number={36},\n  pages={3839--3848},\n  year={2019},\n  publisher={Bentham Science Publishers}\n}"}]