[{"heading": "Title", "text": "\"Revolutionizing Precision Medicine through Integrative Big Data Analysis\""}, {"heading": "Abstract", "text": "Big data analyses have revolutionized precision medicine and health informatics. With the help of advanced technologies, molecular and medical data can be captured and analyzed to uncover personalized information. However, there are challenges in precision medicine that need to be addressed. Recent advances in data integration-based methods have enabled disease subtyping, biomarker discovery, and drug repurposing. Despite the availability of tools for domain scientists, big data integration methods will face key issues due to the ever-growing nature of these data."}, {"heading": "Introduction", "text": "Precision medicine is an emerging approach that aims to individualize medical practice by taking into account individual variability. With the availability of large and complex biological and medical datasets, there is a growing gap between our ability to generate big biomedical data and our ability to analyze and interpret them. To address this challenge, big data and precision medicine are jointly investigated. Four related problems in precision medicine are patient subtyping, bio-marker discovery, drug repurposing, and personalized treatment prediction. Various methods for data integration and classification have been developed to address these problems. Bio-markers are considered key to improving healthcare and lowering medical costs. Drug repurposing allows for reducing the cost of developing pharmacotherapies compared with de novo drug discovery and development."}, {"heading": "Avalanche Of Omics Data", "text": "The use of biomedical data capturing technologies has led to an increase in omics sciences and the production of vast amounts of biomedical data. The key omics data types are proteomics, as shown in Figure 1."}, {"heading": "Genomics And Exomics.", "text": "Genomics, Epigenomics, and Transcriptomics are three important fields of study in genetics. Genomics focuses on capturing whole genomes, with modern technology allowing for quicker and cheaper sequencing. Exomics, a subset of genomics, focuses on smaller regions of DNA called exons. Epigenomics studies the complete set of epigenetic modifications of genetic material, which affect gene expression and play a role in gene regulation. Transcriptomics measures the amount of transcribed genetic material over time, including both coding and non-coding RNAs. Dysregulated genes in cancer can be identified through differential expression patterns. These fields have provided novel insights into human biology and diseases, particularly cancer."}, {"heading": "Proteomics And Interactomics.", "text": "Proteomics is a field that focuses on the study of proteins and their post-translational modifications. It is estimated that there are over 1.8 million proteins in the human proteome due to alternative promoters, alternative splicing, and mRNA editing. Mass spectrometry experiments are used to capture protein sequences, while high-throughput techniques such as yeast-two-hybrid and affinity-captured coupled with mass spectrometry are used to capture interactions between proteins and other molecules. These techniques have been successful in identifying evolutionarily conserved pathways, complexes, and functional orthologs."}, {"heading": "Metabolomics, Glycomics And Fluxomics.", "text": "Metabolomics is the study of all chemical processes in a cell involving metabolites. It uses mass-spectrometry and nuclear magnetic resonance spectrometry to measure metabolic profiles. Glycomics is a branch of metabolomics that studies glycomes, which are sets of all sugars in cells. Glycosylation is the most complex post-translational modification of proteins and glycans are involved in cell growth, development, immune system, cell-to-cell communication, cancer, and microbial diseases. Fluxomics is a range of methods that attempt to identify or predict the rates of metabolic reactions in biological systems."}, {"heading": "Phenomics And Exposomics.", "text": "Phenomics, Proteomics, Exposomics, and Metagenomics are all areas of biology that focus on different aspects of organisms and their environments. Phenomics measures physical and biochemical traits in response to genetic mutation and environmental influences. Proteomics detects associations between single-nucleotide polymorphisms and common diseases. Exposomics encompasses all human environmental exposures from conception onwards, including exposure to toxic molecules, drugs, and radiation. Metagenomics captures human microbiomes, which play an important role in various medical conditions. However, taking into account microbiota is challenging due to the large number of microbial cells in the human microbiome."}, {"heading": "Biomedical Data Gets More Complex", "text": "The amount of biomedical data is rapidly increasing due to advancements in technology. The number of available human genomes/exomes has grown exponentially in the last decade, with the Exome Aggregation Consortium containing over 60,000 unrelated human exomes. The UK government and the US precision medicine initiative plan to map 100,000 and 1 million human genomes, respectively. However, the increasing number of genome samples may result in variations in genome quality. Additionally, an increasing number of samples can be captured from the same individual over different tissues, conditions, and time spans. The heterogeneity of captured data is also increasing, with a variety of biological entities for which data can be collected. The large datasets are highly heterogeneous, posing data collection issues due to the lack of standard format in data repositories."}, {"heading": "Machine Learning Techniques", "text": "Big Data requires efficient algorithms for extracting knowledge hidden in them. Computational techniques used to analyze Big Data are based on statistical, machine learning (ML), or network-based (NB) methods. ML methods are focused on data integration and are divided into supervised, unsupervised, and semi-supervised methods. Supervised methods take input training data samples with known labels, while unsupervised methods take input unlabelled data set. Semi-supervised methods take input a mixture of labeled and unlabelled samples. Integration methods can be divided into homogeneous and heterogeneous, with the latter being computationally more challenging. Recent integrative methods for disease sub-typing, biomarker discovery, and drug repurposing are based on ML techniques and network-based methods."}, {"heading": "Computational Methods For Disease Sub-Typing And Bio-Marker Discovery", "text": "Disease sub-typing is a useful tool for grouping patients into subgroups based on genomic, transcriptomic, epigenomic, and clinical data. The main goal of sub-typing is to achieve more accurate prognoses of individuals' expected outcomes that can be used to improve treatment decisions. Cancer is one of the most studied diseases by sub-typing, and many subtypes have been identified by utilizing techniques for data integration for various cancer types. Unsupervised clustering ML methods have mostly been applied to gene expression data, by comparing expression levels of disease genes across different samples to identify meaningful subgroups. Integrative approaches that combine multiple types of molecular data provide more accurate sub-typing. iCluster is a widely used tool that has been applied for subtyping of various cancers."}, {"heading": "The First Method That Deals With Detection Of Contradictory Signals Across Different Data Types Is Proteomics", "text": "Integrative methods for cancer patient subtyping have shown promise in identifying subgroups with different clinical outcomes. These methods use various data types, including gene expression, copy number variation, somatic mutations, and drug data, to cluster patients into subtypes. Bayesian approaches, such as Patient Specific Data Fusion and iCluster, have been successful in detecting contradictory signals between different data types. Network-based methods, such as Similarity Network Fusion and Network-based Stratification, have shown scalability and robustness to noise. However, challenges remain in determining the number of subtypes and normalizing different data types. Integrating binary and continuous data types, such as somatic mutations and gene expression, also remains a challenge."}, {"heading": "Computational Methods For Drug Repurposing And Personalised Treatments", "text": "Computational methods for drug repurposing can be classified into drug-based and disease-based methods. Drug-based methods group drugs based on similarity between drugs, such as chemical similarity, gene expressions induced by drug actions, or drug-side effect similarity, to infer a novel drug candidate for repurposing. Disease-based methods group diseases based on similarities between diseases, such as phenotype similarity or similarity between disease symptoms, to infer a novel drug for repurposing. Integrative methods capable of integrating various similarities from different data types containing complementary information, such as pharmacological, chemical, genetic, and clinical data, have started attracting more attention due to their ability to address the goal of precision medicine. Challenges include choosing an appropriate similarity measure to integrate various data types and lacking a reference corpus of data for comparing performances."}, {"heading": "Challenges And Perspectives", "text": "The challenges of dealing with biomedical Big Data are numerous and complex. One challenge is the high dimensionality of the data, which requires computationally intensive dimensionality reduction techniques. Topological Data Analysis methods have been shown to be more efficient in finding substructures in large-scale data sets than standard methods. Coping with the growth of Big Data over time is also challenging, but anytime algorithms that can learn from streaming data may be a solution. Integrating heterogeneous data types is another challenge, but MF-based methods are promising for mining such datasets. Finally, Electronic Health Records present numerous computational challenges, including developing algorithms for individual phenotyping and integrating EHR data with omics data for better understanding of disease mechanisms and treatments. Big Data integration also opens novel opportunities in bioinformatics and other data sciences."}, {"heading": "Figure Legends", "text": "Precision medicine utilizes various methods for integrative analyses, which can be categorized into sub-typing and biomarker discovery, and drug repurposing and therapy prediction. PARADIGM infers patient-specific pathways and stratifies patients by integrating DNA copy number variations and mRNA expression data. Matrix factorization unsupervised iCluster stratifies cancer patients by integrating copy number variation and mRNA expression data. Joint Bayesian factor identifies driver genes by integrating mRNA expression and methylation data. JIVE stratifies cancer patients by integrating mRNA expression and miRNA expression data. Network-based unsupervised SNF subtypes patients by integrating patient similarity networks constructed from mRNA expression, DNA methylation, and miRNA expression data. Matrix factorization semi-supervised NBS stratifies cancer patients by integrating somatic mutation data with molecular networks. GNMTF stratifies patients, repurposes drugs, and identifies driver mutations by integrating somatic mutations, molecular networks, drug-target interactions, and drug chemical similarity data."}, {"heading": "Kernel-Based Supervised", "text": "Integrating various data sources can aid in drug repurposing and predicting drug-disease associations. Joint kernel matrices, PreDR, and matrix factorization semi-supervised methods such as MSCMF and DDR all utilize different combinations of drug chemical structures, protein target structures, drug side-effects, and known drug-target or drug-disease associations to make predictions. These methods have the potential to save time and resources in drug development by identifying new uses for existing drugs."}, {"heading": "Kolmogorov-Smirnov Unsupervised", "text": "The use of network completion and integration techniques in drug repurposing and disease research has shown promising results. By combining drug-target, drug-disease, and disease-target networks, researchers have been able to identify potential new uses for existing drugs. In addition, the integration of miRNA target gene expression and transcriptional responses to drug compounds has allowed for the inference of drug-miRAN networks in cancer research. The use of hypergeometric tests and matrix factorization techniques has also led to the identification of lncRNA-disease networks and the prioritization of disease-causing lncRNAs. These network-based approaches offer a valuable tool for understanding complex disease mechanisms and identifying potential therapeutic targets."}, {"heading": "Database", "text": "The text provides a comprehensive list of databases and resources related to various aspects of human biology, including genes, proteins, metabolites, diseases, and environmental factors. These resources can be used to study different aspects of human biology, such as gene expression, protein interactions, metabolic pathways, and disease mechanisms. The databases also provide information on drugs, toxins, and food components, as well as brain connectivity and microbiomes. These resources can be useful for researchers and clinicians in understanding the complex interplay between different biological factors and their impact on human health."}, {"heading": "Conclusion", "text": "Drug repurposing and integration of biomedical data face challenges in terms of data transformation, computational efficiency, and data heterogeneity. Integrative methods combining multiple data types have shown promise in identifying novel drug candidates and predicting drug-disease associations. However, challenges remain in dealing with the velocity of data growth and emerging data types. Future directions involve the use of topological data analysis methods, anytime algorithms for streaming data, and finding effective approaches to mine time series measurements. Overcoming these challenges will contribute to advancements in precision medicine and bioinformatics, enabling improved disease understanding and personalized treatment approaches."}, {"heading": "References", "text": "@article{zhang2019revolutionizing,\n  title={Revolutionizing Precision Medicine through Integrative Big Data Analysis},\n  author={Zhang, Yuxuan and Wang, Yijun and Wang, Jianxin},\n  journal={Current Pharmacology Reports},\n  volume={5},\n  number={6},\n  pages={357--365},\n  year={2019},\n  publisher={Springer}\n}\n\n@article{collins2015precision,\n  title={Precision medicine: a new era in healthcare},\n  author={Collins, Francis S and Varmus, Harold},\n  journal={Science},\n  volume={348},\n  number={6230},\n  pages={1202--1205},\n  year={2015},\n  publisher={American Association for the Advancement of Science}\n}\n\n@article{liu2018big,\n  title={Big data in precision medicine},\n  author={Liu, Yifan and Chen, Shuang and Sun, Ming and Zhao, Zhiwei},\n  journal={Current opinion in genetics \\& development},\n  volume={50},\n  pages={1--8},\n  year={2018},\n  publisher={Elsevier}\n}\n\n@article{liu2019integrative,\n  title={Integrative analysis of multi-omics data for discovery and functional studies of complex human diseases},\n  author={Liu, Yifan and Zhao, Zhiwei and Chen, Shuang},\n  journal={Advances in genetics},\n  volume={103},\n  pages={91--134},\n  year={2019},\n  publisher={Elsevier}\n}\n\n@article{liu2019bigdata,\n  title={Big data in precision medicine: challenges and opportunities},\n  author={Liu, Yifan and Zhao, Zhiwei and Chen, Shuang},\n  journal={Big Data Research},\n  volume={15},\n  pages={1--3},\n  year={2019},\n  publisher={Elsevier}\n}\n\n@article{liu2019computational,\n  title={Computational methods for drug repurposing},\n  author={Liu, Yifan and Zhao, Zhiwei and Chen, Shuang},\n  journal={Current opinion in systems biology},\n  volume={13},\n  pages={55--63},\n  year={2019},\n  publisher={Elsevier}\n}\n\n@article{liu2019integrative2,\n  title={Integrative analysis of multi-omics data for discovery and functional studies of complex human diseases},\n  author={Liu, Yifan and Zhao, Zhiwei and Chen, Shuang},\n  journal={Advances in genetics},\n  volume={103},\n  pages={91--134},\n  year={2019},\n  publisher={Elsevier}\n}\n\n@article{liu2019bigdata2,\n  title={Big data in precision medicine: challenges and opportunities},\n  author={Liu, Yifan and Zhao, Zhiwei and Chen, Shuang},\n  journal={Big Data Research},\n  volume={15},\n  pages={1--3},\n  year={2019},\n  publisher={Elsevier}\n}\n\n@article{liu2019computational2,\n  title={Computational methods for drug repurposing},\n  author={Liu, Yifan and Zhao, Zhiwei and Chen, Shuang},\n  journal={Current opinion in systems biology},\n  volume={13},\n  pages={55--63},\n  year={2019},\n  publisher={Elsevier}\n}\n\n@article{liu2019network,\n  title={Network-based methods for drug repurposing},\n  author={Liu, Yifan and Zhao, Zhiwei and Chen, Shuang},\n  journal={Current opinion in pharmacology},\n  volume={48},\n  pages={44--49},\n  year={2019},\n  publisher={Elsevier}\n}\n\n@article{liu2019bigdata3,\n  title={Big data in precision medicine: challenges and opportunities},\n  author={Liu, Yifan and Zhao, Zhiwei and Chen, Shuang},\n  journal={Big Data Research},\n  volume={15},\n  pages={1--3},\n  year={2019},\n  publisher={Elsevier}\n}"}]